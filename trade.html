<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Chat Face Detection v2 (Single File)</title>

    <!-- Load face-api.js -->
    <script defer src="face-api.min.js"></script>

    <style>
        /* === CSS (Sama seperti sebelumnya) === */
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: #f0f0f0;
            margin: 0;
            padding: 20px;
        }

        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            max-width: 90%; /* Responsiveness */
            width: 700px; /* Fixed width for better layout */
        }

        .video-container {
            position: relative;
            width: 640px; /* Match video width */
            height: 480px; /* Match video height */
            margin-bottom: 20px;
            border: 1px solid #ccc;
            max-width: 100%; /* Responsiveness */
            overflow: hidden; /* Hide overflow if needed */
        }

        #video {
            display: block;
            width: 100%;
            height: 100%;
            object-fit: cover; /* Ensure video covers container */
            transform: scaleX(-1); /* Mirror the video */
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1); /* Mirror the canvas to match video */
        }

        #status {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 15px;
            padding: 8px 15px;
            border-radius: 5px;
            text-align: center;
            min-width: 200px; /* Ensure consistent width */
            transition: background-color 0.3s ease, color 0.3s ease; /* Smooth transition */
        }

        .status-idle { background-color: #ddd; color: #333; }
        .status-detecting { background-color: #ffc107; color: #333; } /* Yellow */
        .status-listening { background-color: #dc3545; color: white; } /* Red */
        .status-processing { background-color: #17a2b8; color: white; } /* Teal */
        .status-speaking { background-color: #28a745; color: white; } /* Green */
        .status-error { background-color: #6c757d; color: white; } /* Grey */
        .status-loading { background-color: #007bff; color: white; } /* Blue */


        #chatbox {
            width: 100%;
            max-width: 640px;
            margin-bottom: 20px;
        }

        #chatlog {
            height: 250px; /* Sedikit lebih tinggi */
            overflow-y: auto;
            border: 1px solid #ccc;
            padding: 10px;
            background-color: #f9f9f9;
            margin-top: 5px;
            border-radius: 4px;
            display: flex;
            flex-direction: column;
        }

        .message {
            margin-bottom: 8px;
            padding: 8px 12px;
            border-radius: 15px; /* Bubble style */
            max-width: 80%; /* Prevent messages from taking full width */
            word-wrap: break-word; /* Wrap long words */
            line-height: 1.4; /* Improve readability */
        }

        .user-message {
            background-color: #007bff; /* Blue */
            color: white;
            margin-left: auto; /* Align to right */
            align-self: flex-end;
            border-bottom-right-radius: 5px; /* Adjust bubble shape */
        }

        .ai-message {
            background-color: #e2e3e5; /* Light grey */
            color: #333;
            margin-right: auto; /* Align to left */
            align-self: flex-start;
            border-bottom-left-radius: 5px; /* Adjust bubble shape */
        }

        #controls {
            text-align: center;
        }

        #startButton {
            padding: 10px 20px;
            font-size: 1em;
            cursor: pointer;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.2s ease;
        }
        #startButton:hover:not(:disabled) {
            background-color: #0056b3;
        }
        #startButton:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }

        /* Responsiveness for smaller screens */
        @media (max-width: 700px) {
            .container {
                 width: 95%;
                 padding: 15px;
            }
            .video-container {
                width: 100%;
                height: auto; /* Adjust height automatically */
                 padding-top: 75%; /* Height/Width = 480/640 = 0.75 */
                 position: relative; /* Needed for absolute positioning of video/canvas */
            }
            #video, #canvas {
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                object-fit: cover;
            }
            #chatbox {
                max-width: 100%;
            }
             h1 {
                 font-size: 1.5em;
             }
             #chatlog {
                 height: 200px; /* Kurangi tinggi di mobile */
             }
        }
        /* === CSS Ends Here === */
    </style>
</head>
<body>
    <h1>AI Chat Face Detection v2</h1>

    <div class="container">
        <div class="video-container">
            <video id="video" width="640" height="480" autoplay muted></video>
            <canvas id="canvas" width="640" height="480"></canvas>
        </div>

        <div id="status" class="status-idle">Idle</div>

        <div id="chatbox">
            <h2>Chat Log</h2>
            <div id="chatlog">
                <!-- Pesan chat akan muncul di sini -->
            </div>
        </div>

         <div id="controls">
             <button id="startButton" >Mulai Deteksi & Chat</button>
             <p><em>Aplikasi akan meminta izin kamera dan mikrofon.</em></p>
             <p><strong>Penting:</strong> Pastikan file <code>face-api.min.js</code> dan folder <code>models</code> berada di folder yang sama.</p>
             <p><strong>Penting:</strong> Pastikan backend di <code>/api/getApiKey</code> berjalan!</p>
         </div>
    </div>

<script>
    // === JavaScript Starts Here ===
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const statusDiv = document.getElementById('status');
    const chatlogDiv = document.getElementById('chatlog');
    const startButton = document.getElementById('startButton');

    // --- Konfigurasi ---
    let TOGETHER_AI_API_KEY = null;
    const TOGETHER_AI_MODEL = "meta-llama/Llama-3-70B-Instruct-Turbo";
    const FACEAPI_MODELS_URL = './models';
    const LIP_MOVEMENT_THRESHOLD = 2.5; // Sensitivitas deteksi gerakan bibir
    const SPEECH_END_TIMEOUT = 1500; // Jeda (ms) TANPA bicara DAN TANPA gerakan bibir sebelum STT selesai
    const MIN_CONFIDENCE = 0.55; // Minimal confidence score deteksi wajah

    // --- State Variables ---
    let faceApiLoaded = false;
    let stream = null;
    let faceDetectionInterval = null;
    let isDetecting = false;
    let faceDetected = false;
    let isListening = false;
    let isSpeaking = false;
    let recognition = null;
    // Hapus speechTimeout, diganti cek di face detection loop
    let lastLipPosition = null;
    let synth = window.speechSynthesis;
    let currentUtterance = null;
    let userHasStarted = false;
    let lastSignificantMovementTime = Date.now(); // Waktu terakhir gerakan bibir signifikan
    let lastResultTime = Date.now(); // Waktu terakhir ada hasil STT (interim/final)

    // --- API Key Fetching (Sama seperti sebelumnya) ---
    async function getApiKey() {
        console.log("Mencoba mengambil API Key dari /api/getApiKey...");
        updateStatus("Fetching API Key...", "status-loading");
        try {
            const response = await fetch('/api/getApiKey');
            if (!response.ok) {
                 throw new Error(`HTTP error! status: ${response.status}`);
            }
            const data = await response.json();
            if (data.apiKey) {
                TOGETHER_AI_API_KEY = data.apiKey;
                console.log('API Key berhasil diambil.');
                updateStatus("API Key Loaded", "status-idle");
                return true;
            } else {
                throw new Error('API key not found in response');
            }
        } catch (error) {
            console.error('Gagal ambil API Key:', error);
            updateStatus("Gagal Ambil API Key!", "status-error");
            alert("Gagal mengambil API Key dari server. Pastikan backend berjalan dan endpoint /api/getApiKey benar.\n\nError: " + error.message);
            TOGETHER_AI_API_KEY = null;
            return false;
        }
    }


    // --- Setup Speech Recognition (STT) ---
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.continuous = true; // Set true agar terus berjalan sampai di stop manual
        recognition.interimResults = true;
        recognition.lang = 'id-ID';

        recognition.onstart = () => {
            console.log("STT: Mulai mendengarkan...");
            isListening = true;
            updateStatus("Listening...", "status-listening");
            lastResultTime = Date.now(); // Reset timer hasil saat mulai
            lastSignificantMovementTime = Date.now(); // Reset timer gerakan juga
        };

        recognition.onresult = (event) => {
            lastResultTime = Date.now(); // Ada hasil baru, reset timer hasil

            let interimTranscript = '';
            let finalTranscript = '';
            let currentFinalBuffer = ""; // Buffer final dari event ini saja

            for (let i = event.resultIndex; i < event.results.length; ++i) {
                const transcriptPart = event.results[i][0].transcript;
                if (event.results[i].isFinal) {
                    finalTranscript += transcriptPart + " "; // Tambah spasi antar final part
                     currentFinalBuffer += transcriptPart + " ";
                } else {
                    interimTranscript += transcriptPart;
                }
            }

            // Hanya log/tampilkan interim jika ada
            if (interimTranscript) console.log("STT Interim:", interimTranscript);

            // Gabungkan hasil final ke buffer utama
            if (currentFinalBuffer.trim()) {
                console.log("STT Final Fragment:", currentFinalBuffer.trim());
                recognition.finalTranscriptBuffer = (recognition.finalTranscriptBuffer || "") + currentFinalBuffer;
            }

            // Timeout/logic henti bicara TIDAK lagi ditangani di sini, tapi di face detection loop
        };

        recognition.onerror = (event) => {
            console.error("STT Error:", event.error);
            if (event.error === 'no-speech') {
                console.log("STT: No speech detected (ignored, continuous mode).");
                // Di mode continuous, ini mungkin terjadi antar ucapan, biarkan saja
                // Reset timer mungkin?
                // lastResultTime = Date.now();
            } else if (event.error === 'aborted') {
                console.log("STT: Aborted.");
                // Ini bisa terjadi jika kita stop manual, atau krn hal lain
            } else if (event.error === 'audio-capture') {
                updateStatus(`STT Error: Mic Problem?`, "status-error");
                alert("Terjadi masalah dengan mikrofon.");
                 isListening = false; // Pastikan state false
                 if (!isSpeaking) updateStatus("Error", "status-error"); // Update status jika tidak sedang bicara
            }
            else {
                 updateStatus(`STT Error: ${event.error}`, "status-error");
                 isListening = false; // Set false jika error serius
                 if (!isSpeaking) updateStatus("Error", "status-error");
            }
             // Jika error, state isListening mungkin perlu direset di onend
        };

        recognition.onend = () => {
            console.log("STT: Recognition service ended.");
            // Penting: Set isListening false HANYA di sini (atau saat error parah)
            const wasListening = isListening;
            isListening = false;

            // Jangan proses buffer di sini, karena stop bisa terjadi karena berbagai alasan
            // (misal kehilangan wajah, interupsi TTS, atau stop manual).
            // Pemrosesan buffer HANYA dilakukan oleh `stopListeningAndProcess` yg dipicu oleh inactivity.

             // Reset buffer jika stop bukan karena inactivity timeout
             // Tapi bagaimana cara tahu? Mungkin lebih aman reset buffer saat startListening saja.
             // recognition.finalTranscriptBuffer = "";

            // Update status HANYA jika stop terjadi saat tidak ada TTS
            if (!isSpeaking && userHasStarted) {
                 if (faceDetected) {
                     // Jika wajah masih ada tapi stop, berarti mungkin baru selesai proses AI
                     // atau stop manual, kembali ke state 'detecting' siap dengar lagi
                     updateStatus("Face Detected", "status-detecting");
                 } else {
                     // Jika wajah hilang saat stop
                     updateStatus("Idle (Waiting for face)", "status-idle");
                 }
            } else if (!isSpeaking && !userHasStarted) {
                 updateStatus("Deteksi Dihentikan", "status-idle");
            }
             console.log(`STT ended. Was listening: ${wasListening}, Is now listening: ${isListening}`);

        };

        recognition.finalTranscriptBuffer = ""; // Initialize buffer

    } else {
        console.error("Browser tidak support Web Speech API.");
        alert("Maaf, browser Anda tidak mendukung fitur Speech Recognition.");
        startButton.disabled = true;
    }

    // --- Setup Text-to-Speech (TTS) (Sama seperti sebelumnya) ---
    synth.onvoiceschanged = () => {
        const voices = synth.getVoices();
        console.log("Available TTS voices:", voices.map(v => ({ name: v.name, lang: v.lang })));
    };

    function speak(text) {
        if (synth.speaking) {
            console.warn("TTS: Masih ada yang diucapkan, membatalkan...");
            synth.cancel();
            setTimeout(() => speak(text), 150);
            return;
        }
        if (!text || text.trim() === "") {
             console.warn("TTS: Teks kosong, tidak ada yang diucapkan.");
             if (faceDetected && !isListening && userHasStarted) {
                 // Jika AI tidak merespon apa2, dan wajah ada, langsung siap dengar lagi
                 updateStatus("Face Detected", "status-detecting");
                 startListening(); // Langsung aktifkan mic jika AI diam
             }
             return;
        }

        addMessage("AI", text);

        currentUtterance = new SpeechSynthesisUtterance(text);
        const indonesianVoice = synth.getVoices().find(voice => voice.lang === 'id-ID');
        if (indonesianVoice) {
            currentUtterance.voice = indonesianVoice;
            console.log("Using TTS voice:", indonesianVoice.name);
        } else {
            console.warn("TTS: Suara Bahasa Indonesia tidak ditemukan, menggunakan default.");
        }
        currentUtterance.lang = 'id-ID';
        currentUtterance.rate = 1;
        currentUtterance.pitch = 1;

        currentUtterance.onstart = () => {
            console.log("TTS: Mulai berbicara...");
            isSpeaking = true;
            updateStatus("Speaking...", "status-speaking");
            // Hentikan STT jika sedang berjalan saat TTS mulai
            if (isListening) {
                 console.log("TTS: Menghentikan STT karena AI mulai bicara.");
                 // Jangan proses buffer di sini, AI yang bicara
                 recognition.stop(); // Hentikan STT
            }
        };

        currentUtterance.onend = () => {
            console.log("TTS: Selesai berbicara.");
            isSpeaking = false;
            currentUtterance = null;
             // Setelah TTS selesai, jika wajah masih terdeteksi, langsung aktifkan STT lagi
            if (faceDetected && userHasStarted && !isListening) {
                 console.log("TTS Selesai, mengaktifkan STT...");
                 updateStatus("Face Detected", "status-detecting"); // Update status dulu
                 startListening(); // Langsung dengarkan lagi
            } else if (!faceDetected && userHasStarted) {
                 updateStatus("Idle (Waiting for face)", "status-idle");
            }
        };

        currentUtterance.onerror = (event) => {
            console.error("TTS Error:", event.error);
            isSpeaking = false;
            currentUtterance = null;
            updateStatus(`TTS Error: ${event.error}`, "status-error");
             // Jika error TTS, coba aktifkan STT jika wajah terdeteksi
             if (faceDetected && userHasStarted && !isListening) {
                 console.log("TTS Error, mengaktifkan STT...");
                 updateStatus("Face Detected", "status-detecting"); // Update status dulu
                 startListening();
             } else if (!faceDetected && userHasStarted) {
                 updateStatus("Idle (Waiting for face)", "status-idle");
             }
        };

        synth.speak(currentUtterance);
    }

    function stopTTS() {
        if (synth.speaking) {
            console.log("TTS: Membatalkan ucapan (interupsi).");
            isSpeaking = false; // Set state SEBELUM cancel
            synth.cancel(); // Ini akan trigger onend atau onerror
        }
    }

    // --- Face Detection Logic ---
    async function loadFaceApiModels() { // Sama
        try {
            console.log("Memuat model face-api.js...");
            updateStatus("Loading Face Models...", "status-loading");
            await Promise.all([
                faceapi.nets.tinyFaceDetector.loadFromUri(FACEAPI_MODELS_URL),
                faceapi.nets.faceLandmark68Net.loadFromUri(FACEAPI_MODELS_URL),
            ]);
            console.log("Model face-api.js berhasil dimuat.");
            faceApiLoaded = true;
            updateStatus("Models Loaded", "status-idle")
        } catch (error) {
            console.error("Gagal memuat model face-api.js:", error);
            updateStatus("Error Loading Models", "status-error");
            alert("Gagal memuat model face detection. Pastikan model ada di folder 'models'.\n\nError: " + error.message);
            throw error;
        }
    }

    async function startVideo() { // Sama
        try {
            console.log("Meminta izin kamera & mikrofon...");
            updateStatus("Requesting Permissions...", "status-loading");
            stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: true });
            video.srcObject = stream;
            console.log("Akses kamera dan mikrofon berhasil.");
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    video.play();
                    console.log("Video metadata loaded and playing.");
                    resolve();
                };
                 setTimeout(resolve, 500); // Fallback
            });
        } catch (err) {
            console.error("Error mengakses kamera/mikrofon:", err);
            updateStatus("Permission Error", "status-error");
            alert("Tidak bisa mengakses kamera atau mikrofon. Pastikan izin diberikan dan tidak ada aplikasi lain yang menggunakan kamera/mikrofon.\n\nError: " + err.message);
            throw err;
        }
    }

    function startFaceDetection() {
        if (!faceApiLoaded || !stream || isDetecting) return;

        isDetecting = true;
        console.log("Memulai deteksi wajah...");
        lastSignificantMovementTime = Date.now(); // Reset timer
        lastResultTime = Date.now(); // Reset timer

        const displaySize = { width: video.videoWidth || 640, height: video.videoHeight || 480 };
        faceapi.matchDimensions(canvas, displaySize);

        faceDetectionInterval = setInterval(async () => {
            if (!isDetecting || video.paused || video.ended) return;

            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 224 }))
                                          .withFaceLandmarks();

            const context = canvas.getContext('2d');
            context.clearRect(0, 0, canvas.width, canvas.height);

            let currentFaceDetected = false; // Status deteksi di frame ini
            let lipsMoved = false; // Status gerakan bibir di frame ini

            if (detections && detections.length > 0) {
                const detection = detections[0];
                if (detection.detection.score >= MIN_CONFIDENCE) {
                    // Wajah terdeteksi di frame ini
                    currentFaceDetected = true;

                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections); // Gambar landmark

                    // Cek gerakan bibir (sama seperti sebelumnya)
                    const landmarks = detection.landmarks;
                    const mouth = landmarks.getMouth();
                    let currentLowerLipY = 0;
                    mouth.slice(16, 20).forEach(pt => currentLowerLipY += pt.y); // Bibir bawah
                    currentLowerLipY /= 4;

                    if (lastLipPosition !== null) {
                        const diff = Math.abs(currentLowerLipY - lastLipPosition);
                        if (diff > LIP_MOVEMENT_THRESHOLD) {
                            lipsMoved = true;
                            lastSignificantMovementTime = Date.now(); // Update HANYA jika bergerak
                             // console.log("Lip movement detected:", diff.toFixed(2)); // Kurangi log ini
                        }
                    }
                    lastLipPosition = currentLowerLipY;
                }
            }

            // --- Logika Utama berdasarkan status deteksi frame ini ---

            if (currentFaceDetected) {
                // Jika Wajah BARU terdeteksi (sebelumnya tidak)
                if (!faceDetected) {
                    console.log("Wajah terdeteksi.");
                    faceDetected = true;
                    // Langsung mulai listening jika tidak sedang bicara AI
                    if (!isSpeaking && !isListening && userHasStarted) {
                         console.log("Wajah terdeteksi, memulai STT...");
                         startListening();
                    } else if (!isSpeaking && !isListening) {
                         updateStatus("Face Detected", "status-detecting"); // Update status jika belum start
                    }
                }

                // --- Kondisi saat Wajah Terdeteksi ---

                // 1. Interupsi TTS jika bibir bergerak
                if (isSpeaking && lipsMoved) {
                    console.log("User interruption detected during TTS!");
                    stopTTS(); // Hentikan AI bicara
                    // Beri jeda SANGAT singkat lalu mulai STT
                    setTimeout(() => {
                        // Cek lagi state setelah stopTTS (yg async)
                        if (faceDetected && !isListening && !isSpeaking && userHasStarted) {
                            console.log("Restarting STT after TTS interruption.");
                            startListening();
                        } else {
                             console.log(`Tidak start STT post-interrupt: face=${faceDetected}, listen=${isListening}, speak=${isSpeaking}`);
                        }
                    }, 50); // Jeda sangat singkat
                }

                // 2. Cek kondisi henti bicara (hanya jika sedang mendengarkan)
                if (isListening) {
                    const timeSinceLastResult = Date.now() - lastResultTime;
                    const timeSinceLastMovement = Date.now() - lastSignificantMovementTime;

                    // Kondisi: Sudah cukup lama sejak hasil STT TERAKHIR DITERIMA
                    // DAN sudah cukup lama sejak BIBIR BERGERAK TERAKHIR
                    if (timeSinceLastResult > SPEECH_END_TIMEOUT && timeSinceLastMovement > SPEECH_END_TIMEOUT) {
                        console.log(`Speech end condition met: No result for ${timeSinceLastResult}ms, no movement for ${timeSinceLastMovement}ms`);
                        // Ambil buffer SEBELUM stop listening
                         const transcriptBuffer = recognition.finalTranscriptBuffer ? recognition.finalTranscriptBuffer.trim() : "";
                         if (transcriptBuffer !== "") {
                             console.log("Stopping listening and processing due to inactivity.");
                             // PENTING: Panggil fungsi khusus yg handle stop & process
                             stopListeningAndProcess(transcriptBuffer);
                         } else {
                             // Timeout tapi tidak ada buffer? Mungkin user diam dari awal.
                             // Jangan kirim apa2, cukup stop listening agar tidak jalan terus.
                              console.log("Inactivity timeout without transcript buffer, stopping listening only.");
                              stopListening();
                              // Reset timer agar tidak langsung re-trigger jika user tetap diam
                              lastResultTime = Date.now();
                              lastSignificantMovementTime = Date.now();
                         }
                    }
                }

            } else {
                // Jika Wajah TIDAK terdeteksi di frame ini
                if (faceDetected) {
                    // Jika sebelumnya terdeteksi (baru saja hilang)
                    console.log("Wajah tidak terdeteksi.");
                    faceDetected = false; // Update state global
                    lastLipPosition = null;
                    handleNoFaceDetected(); // Panggil fungsi handler
                }
                // Jika memang sudah tidak terdeteksi, tidak perlu lakukan apa-apa
            }

        }, 150); // Interval deteksi (ms)
    }

    function handleNoFaceDetected() {
        // Fungsi ini dipanggil saat wajah hilang (transisi dari terdeteksi -> tidak)
        console.log("Handling face lost...");
        // Hentikan STT jika sedang berjalan
        if (isListening) {
            console.log("Mematikan STT karena wajah hilang.");
            // Jangan proses buffer jika wajah hilang di tengah bicara
             recognition.finalTranscriptBuffer = ""; // Kosongkan buffer
             stopListening(); // Hentikan STT
        }

        // Update status HANYA jika AI tidak sedang bicara
        if (!isSpeaking && userHasStarted) {
           updateStatus("Idle (Waiting for face)", "status-idle");
        }
         // Bersihkan canvas
         const context = canvas.getContext('2d');
         if (context) context.clearRect(0, 0, canvas.width, canvas.height);
    }

    function stopFaceDetection() { // Sedikit modifikasi cleanup
        console.log("Stopping face detection and streams...");
        isDetecting = false;
        if (faceDetectionInterval) clearInterval(faceDetectionInterval);
        faceDetectionInterval = null;

        handleNoFaceDetected(); // Pastikan STT berhenti jika masih jalan

        if (stream) {
            stream.getTracks().forEach(track => track.stop());
            stream = null;
            video.srcObject = null;
            console.log("Media streams stopped.");
        }
        // Hentikan TTS jika masih jalan
        if (isSpeaking) {
            stopTTS();
        }
        faceDetected = false;
        lastLipPosition = null;
        setTimeout(() => { // Cleanup canvas setelah jeda
            const context = canvas.getContext('2d');
            if (context) context.clearRect(0, 0, canvas.width, canvas.height);
        }, 100);
        updateStatus("Deteksi Dihentikan", "status-idle");
        console.log("Detection stopped.");
    }

    function startListening() {
        // Pastikan kondisi memungkinkan untuk start
        if (!recognition || isListening || isSpeaking || !faceDetected || !userHasStarted) {
             console.log(`Cannot start listening: isListening=${isListening}, isSpeaking=${isSpeaking}, faceDetected=${faceDetected}, started=${userHasStarted}`);
             // Jika gagal start krn TTS, status harusnya sudah speaking.
             // Jika gagal start krn sudah listening, abaikan.
             // Jika gagal start krn wajah hilang, status sudah idle.
             // Jika gagal start krn belum mulai, abaikan.
             return;
        }
        try {
            // Reset buffer SEBELUM start
            recognition.finalTranscriptBuffer = "";
            recognition.start();
            // State isListening akan di set true di onstart
        } catch (e) {
             console.error("Error starting STT:", e.message);
             // Handle InvalidStateError jika user klik start/stop terlalu cepat
            if (e.name === 'InvalidStateError') {
                 console.warn("STT already starting/stopping? Ignoring.");
            } else {
                 updateStatus("STT Start Error", "status-error");
            }
        }
    }

    function stopListening() {
        if (recognition && isListening) { // Hanya stop jika benar2 sedang listening
            console.log("Requesting STT stop...");
            recognition.stop(); // Ini akan trigger onend, yang akan set isListening = false
        } else if (recognition && !isListening){
             console.log("StopListening called but not currently listening.");
             // Mungkin recognition masih dalam proses stop? Abaikan saja.
        }
    }

    // Fungsi BARU untuk menangani stop karena inactivity timeout DAN kirim ke AI
    function stopListeningAndProcess(transcript) {
         if (!isListening) {
              console.warn("stopListeningAndProcess called but not listening. Aborting process.");
              return;
         }
         console.log("Stopping listening to process transcript:", transcript);

         // 1. Hentikan STT dulu
         stopListening(); // Ini akan memanggil onend -> set isListening = false

         // 2. Proses teks jika ada
         if (transcript && transcript.trim() !== "") {
             // Langsung panggil processSpeechResult
             processSpeechResult(transcript.trim());
         } else {
              console.log("Transcript buffer was empty, nothing sent to AI.");
              // Jika tidak ada yg dikirim ke AI, dan wajah masih ada, siap listen lagi
              if (faceDetected && !isSpeaking && userHasStarted) {
                  updateStatus("Face Detected", "status-detecting");
                  // Jangan auto start, tunggu TTS (jika ada) selesai atau user bicara lagi
              }
         }
         // Buffer sudah diambil sbg argumen, reset di startListening berikutnya
         // recognition.finalTranscriptBuffer = "";
    }


    function processSpeechResult(text) { // Sedikit penyesuaian prompt
        if (!text || text.trim() === "") return;

        addMessage("User", text);
        updateStatus("Processing AI...", "status-processing");

        // Konteks bisa lebih simpel atau kompleks sesuai kebutuhan
        const faceContext = "Pengguna sedang berinteraksi melalui video."; // Konteks umum

        // Struktur prompt untuk model instruct (sesuaikan jika perlu)
        // const fullPrompt = `System: Anda adalah asisten AI percakapan.\nUser: ${text}\nAssistant:`;
        const fullPrompt = text; // Coba kirim teks user langsung jika modelnya chat-tuned

        sendToTogetherAI(fullPrompt);
    }

    // --- AI Interaction (Together AI) (Sama seperti sebelumnya) ---
    async function sendToTogetherAI(prompt) {
        if (!TOGETHER_AI_API_KEY) {
            console.error("API Key Together AI belum diambil atau tidak valid!");
            updateStatus("API Key Missing!", "status-error");
            speak("Maaf, saya tidak bisa memproses permintaan Anda karena ada masalah dengan konfigurasi API key.");
            return;
        }

        console.log("Sending prompt to Together AI:", prompt);
        updateStatus("AI Thinking...", "status-processing");
        const apiUrl = "https://api.together.xyz/v1/chat/completions";

        try {
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${TOGETHER_AI_API_KEY}`
                },
                body: JSON.stringify({
                    model: TOGETHER_AI_MODEL,
                    messages: [
                        // { role: "system", content: "Anda adalah asisten AI yang ramah dalam Bahasa Indonesia." },
                        { role: "user", content: prompt }
                    ],
                    max_tokens: 250,
                    temperature: 0.7, // Naikkan sedikit untuk Llama 3?
                    top_p: 0.9,
                    // stop: ["\nUser:", "<|eot_id|>"], // Stop sequence jika perlu
                })
            });

            if (!response.ok) {
                const errorData = await response.json().catch(() => ({ message: 'Failed to parse error response' }));
                console.error("Error from Together AI:", response.status, errorData);
                 let errMsg = `API Error ${response.status}`;
                 if (errorData && errorData.error && errorData.error.message) errMsg += `: ${errorData.error.message}`;
                 else if (errorData && errorData.message) errMsg += `: ${errorData.message}`;
                 throw new Error(errMsg);
            }

            const data = await response.json();
            console.log("Response from Together AI:", data);

            const aiText = data.choices && data.choices[0] && data.choices[0].message && data.choices[0].message.content
                           ? data.choices[0].message.content.trim()
                           : "Maaf, saya tidak dapat memproses respons dari AI saat ini.";

            speak(aiText); // Ucapkan respons AI

        } catch (error) {
            console.error("Error sending request to Together AI:", error);
            updateStatus("AI Network Error", "status-error");
            // Coba berikan pesan error yang lebih informatif jika mungkin
             let speakErrMsg = "Maaf, terjadi kesalahan saat menghubungi AI.";
             if (error.message.includes("API Error 4")) speakErrMsg = "Maaf, ada masalah dengan permintaan ke AI.";
             if (error.message.includes("fetch")) speakErrMsg = "Maaf, ada masalah jaringan saat menghubungi AI.";

            speak(speakErrMsg);

             // Jika error AI, kembali ke state siap mendengar jika wajah ada
             if (faceDetected && userHasStarted && !isListening && !isSpeaking) {
                  console.log("AI Error, mengaktifkan STT...");
                  updateStatus("Face Detected", "status-detecting");
                  startListening();
             } else if (!faceDetected && userHasStarted) {
                  updateStatus("Idle (Waiting for face)", "status-idle");
             }
        }
    }

    // --- UI Update Functions (Sama seperti sebelumnya) ---
    function updateStatus(message, className) {
        if (statusDiv.textContent !== message || !statusDiv.classList.contains(className)) {
             statusDiv.textContent = message;
             statusDiv.className = '';
             statusDiv.classList.add(className);
        }
    }

    function addMessage(sender, text) {
        const messageDiv = document.createElement('div');
        messageDiv.classList.add('message');
        messageDiv.classList.add(sender === 'User' ? 'user-message' : 'ai-message');
        messageDiv.textContent = text;
        chatlogDiv.appendChild(messageDiv);
        chatlogDiv.scrollTo({ top: chatlogDiv.scrollHeight, behavior: 'smooth' });
    }

    // --- Event Listener Start/Stop Button (Sama seperti sebelumnya) ---
    startButton.addEventListener('click', async () => {
         if (!userHasStarted) {
             // --- Start Sequence ---
             startButton.textContent = "Memulai...";
             startButton.disabled = true;


             try {
                 const apiKeyFetched = await getApiKey();
                 if (!apiKeyFetched) throw new Error("API Key fetch failed");

                 await loadFaceApiModels();
                 if (!faceApiLoaded) throw new Error("Face API models load failed");

                 await startVideo();

                  // Setelah video siap, baru set userHasStarted dan mulai deteksi
                  userHasStarted = true; // Pindah ke sini
                  startFaceDetection(); // Mulai loop deteksi

                 startButton.textContent = "Hentikan Deteksi";

             } catch (error) {
                 console.error("Gagal memulai:", error);
                 stopFaceDetection(); // Cleanup
                 userHasStarted = false; // Reset flag
                 startButton.textContent = "Mulai Deteksi & Chat";
                 updateStatus("Initialization Failed", "status-error");
             } finally {
                 startButton.disabled = false;
             }

         } else {
             // --- Stop Sequence ---
              userHasStarted = false; // Set flag false DULU
              stopFaceDetection();
              startButton.textContent = "Mulai Deteksi & Chat";
         }
    });

    // --- Initial Check (Sama seperti sebelumnya) ---
    if (!SpeechRecognition) {
        startButton.disabled = true;
        updateStatus("Browser Not Supported", "status-error");
        alert("Web Speech API tidak didukung di browser ini. Coba gunakan Chrome.");
    } else {
         updateStatus("Ready (Click Start)", "status-idle");
    }

    // --- Cleanup on Close (Sama seperti sebelumnya) ---
    window.addEventListener('beforeunload', (event) => {
        if (userHasStarted) {
            stopFaceDetection();
        }
    });

    console.log("AI Chat Interface Ready (v2).");
    // === JavaScript Ends Here ===
</script>

</body>
</html>
