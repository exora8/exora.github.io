<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Chat (Debug STT Response)</title>

    <style>
        /* --- CSS (Sama seperti sebelumnya) --- */
        body { font-family: sans-serif; line-height: 1.6; margin: 20px; background-color: #f4f4f4; color: #333; }
        .container { max-width: 700px; margin: auto; background: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        h1, h2 { text-align: center; color: #555; }
        .video-container { position: relative; margin-bottom: 15px; text-align: center; background-color: #eee; padding: 10px; border-radius: 5px; min-height: 260px; /* Ensure space */}
        #webcamVideo { border: 1px solid #ccc; display: block; margin: 0 auto; background-color: #333; /* Dark bg while loading */ }
        #overlayCanvas { position: absolute; top: 10px; left: 50%; transform: translateX(-50%); pointer-events: none; }
        .status-area { text-align: center; margin-bottom: 20px; padding: 10px; background-color: #e9e9e9; border-radius: 5px; }
        #status { font-weight: bold; display: inline-block; min-width: 150px; text-align: left; }
        button { padding: 8px 15px; margin: 5px; cursor: pointer; border: none; border-radius: 4px; background-color: #007bff; color: white; font-size: 0.9em; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }
        button:hover:not(:disabled) { background-color: #0056b3; }
        .text-display { margin-top: 20px; border-top: 1px solid #eee; padding-top: 15px; }
        .text-display h2 { font-size: 1.1em; color: #666; margin-bottom: 5px; }
        .text-display p { background-color: #f9f9f9; border: 1px solid #ddd; padding: 10px; min-height: 40px; border-radius: 4px; white-space: pre-wrap; }
        .warning { color: red; font-weight: bold; text-align: center; margin-bottom: 10px; }
    </style>

    <!-- **** WAJIB: Sertakan face-api.js **** -->
    <script defer src="face-api.min.js"></script>

</head>
<body>
    <h1>Ngobrol sama AI (Debug STT)</h1>
    <p class="warning">Buka Console (F12) untuk melihat log detail STT (onstart, onerror, onend).</p>

    <div class="container">
        <div class="video-container">
            <video id="webcamVideo" width="320" height="240" autoplay muted playsinline></video>
            <canvas id="overlayCanvas" width="320" height="240"></canvas>
        </div>

        <div class="status-area">
            <p>Status: <span id="status">Initializing...</span></p>
            <button id="manualStartButton" disabled>Mulai Bicara (Manual)</button>
            <button id="manualStopButton" disabled>Berhenti Bicara (Manual)</button>
        </div>

        <div class="text-display">
            <h2>Transkrip Kamu:</h2>
            <p id="user-text">...</p>
            <h2>Respon AI:</h2>
            <p id="ai-text">...</p>
        </div>
    </div>

    <script>
        // --- JavaScript Starts Here ---

        // --- Konfigurasi ---
        let API_KEY;
        const TOGETHER_AI_MODEL = "meta-llama/Llama-3-70B-Instruct-Turbo";
        const TOGETHER_AI_URL = "https://api.together.xyz/v1/chat/completions";

        // --- Referensi Elemen DOM ---
        const statusDisplay = document.getElementById('status');
        const userTextDisplay = document.getElementById('user-text');
        const aiTextDisplay = document.getElementById('ai-text');
        const manualStartButton = document.getElementById('manualStartButton');
        const manualStopButton = document.getElementById('manualStopButton');
        const videoElement = document.getElementById('webcamVideo');
        const canvasElement = document.getElementById('overlayCanvas');

        // --- State Aplikasi ---
        let isListening = false;
        let isSpeakingAI = false;
        let isProcessing = false;
        let finalTranscript = '';
        let recognition;
        let synthesis = window.speechSynthesis;
        let currentUtterance = null;
        let faceApiReady = false;
        let detectionInterval;
        let stillnessCheckAllowed = true; // Flag untuk masa tenggang stillness check

        // --- State Deteksi Wajah ---
        let mouthOpenThreshold = 10; // Tune this value
        let headMovementThreshold = 5; // Tune this value
        let lastMouthState = 'closed';
        let mouthMovementStart = null;
        let headStillStart = null;
        let mouthStillStart = null;
        let lastHeadPosition = null;
        let faceDetectedConfidence = 0.6; // Tune this value

        // --- Konfigurasi Waktu Trigger (ms) ---
        const MOUTH_MOVEMENT_CONFIRM_DURATION = 300;
        const HEAD_STILL_CONFIRM_DURATION = 1000;
        const MOUTH_STILL_CONFIRM_DURATION = 1200;
        const DETECTION_INTERVAL_MS = 100;
        const STILLNESS_GRACE_PERIOD_MS = 500; // Jeda 0.5 detik setelah STT start

        // --- Fungsi API Key ---
        async function getApiKey() {
            try { /* ... (Kode getApiKey sama) ... */
                const response = await fetch('/api/getApiKey');
                if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
                const data = await response.json();
                if (!data.apiKey) throw new Error('Invalid API key response format.');
                API_KEY = data.apiKey; console.log('API Key fetched.');
            } catch (error) { /* ... (handle error sama) ... */
                console.error('Failed to fetch API Key:', error); statusDisplay.textContent = 'Error: No API Key!';
                alert(`Cannot fetch config: ${error.message}.`); manualStartButton.disabled = true; manualStopButton.disabled = true;
            }
        }

        // --- Inisialisasi Web Speech API (DENGAN LOG DETAIL) ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
            statusDisplay.textContent = 'Error: Browser no support STT.';
            alert('Browser tidak support Web Speech API (STT).');
        } else {
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'id-ID';

            recognition.onstart = () => {
                // **** LOG PENTING ****
                console.log("✅✅✅ Speech Recognition ONSTART fired!");
                isListening = true;
                // Reset stillness check flag dan mulai timer masa tenggang
                stillnessCheckAllowed = false;
                console.log(`[TIMER] Stillness check BLOCKED for ${STILLNESS_GRACE_PERIOD_MS}ms`);
                setTimeout(() => {
                    console.log("[TIMER] Stillness check is now ALLOWED.");
                    stillnessCheckAllowed = true;
                }, STILLNESS_GRACE_PERIOD_MS);
                updateStatusDisplay();
                updateManualButtonStates();
            };

            recognition.onresult = (event) => {
                let interimTranscript = '';
                finalTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript;
                    } else {
                        interimTranscript += event.results[i][0].transcript;
                    }
                }
                // Tampilkan hasil sementara dan final
                console.log("STT Result: Final='", finalTranscript, "' Interim='", interimTranscript, "'");
                userTextDisplay.textContent = finalTranscript + interimTranscript;
            };

            recognition.onend = () => {
                // **** LOG PENTING ****
                console.log("⏹️⏹️⏹️ Speech Recognition ONEND fired.");
                isListening = false;
                // Pastikan stillness check diizinkan lagi jika STT berhenti karena alasan lain
                stillnessCheckAllowed = true;
                updateStatusDisplay();
                updateManualButtonStates();
            };

            recognition.onerror = (event) => {
                // **** LOG PENTING ****
                console.error("❌❌❌ Speech Recognition ONERROR fired!", event.error, event.message);
                isListening = false; // Reset state
                stillnessCheckAllowed = true; // Izinkan cek lagi jika error
                let errorMsg = `Error STT: ${event.error}`;
                if (event.message) errorMsg += ` (${event.message})`;
                statusDisplay.textContent = errorMsg;
                alert(`Problem with speech recognition: ${event.error}. Check console (F12) for details.`);
                updateStatusDisplay(); // Update status
                updateManualButtonStates();
            };
        }

        if (!synthesis) { /* ... (handle TTS support sama) ... */ }

        // --- Fungsi Inti STT, AI, TTS (Tidak banyak berubah) ---
        function startListening() {
            if (!API_KEY || !recognition || !faceApiReady) {
                console.error("Cannot start listening: Prerequisites not met.", { API_KEY: !!API_KEY, recognition: !!recognition, faceApiReady });
                alert("Cannot start listening. Check API Key, Face Detection, and Mic Permission.");
                return;
            }
            if (isListening || isProcessing || isSpeakingAI) {
                console.warn("Attempted to start listening while already active.");
                return;
            }
            console.log("Attempting to start listening (triggered)...");
            finalTranscript = '';
            userTextDisplay.textContent = '...';
            aiTextDisplay.textContent = '...';
            try {
                recognition.start(); // onstart/onerror akan handle sisanya
            } catch (e) {
                 console.error("Error executing recognition.start():", e);
                 statusDisplay.textContent = `Error starting STT: ${e.name}`;
                 alert(`Could not start microphone: ${e.message}. Check permissions.`);
                 isListening = false;
                 stillnessCheckAllowed = true; // Izinkan cek lagi jika gagal start
                 updateManualButtonStates();
                 updateStatusDisplay();
            }
        }

        function stopListeningAndProcess() {
            // Hanya stop jika memang sedang listening
            if (!isListening || !recognition) {
                 console.warn("Attempted to stop listening when not active.");
                 return;
            }
            console.log("Stopping listening and processing...");
             try {
                 recognition.stop(); // Akan memicu onend
             } catch (e) { console.warn("Error stopping recognition:", e); }
            isListening = false; // Set state langsung
            isProcessing = true; // Mulai proses
            stillnessCheckAllowed = true; // Izinkan cek lagi setelah stop
            updateStatusDisplay();
            updateManualButtonStates();

            const textToSend = finalTranscript.trim();
            console.log("Final transcript to send:", textToSend);

            if (textToSend) {
                sendToAI(textToSend);
            } else {
                console.log("No final transcript to send.");
                isProcessing = false; // Tidak ada yg diproses
                statusDisplay.textContent = 'No speech detected.';
                updateStatusDisplay();
                updateManualButtonStates();
            }
        }

        async function sendToAI(userMessage) { /* ... (Kode sendToAI sama) ... */
            if (!API_KEY) { console.error("No API Key"); /*...*/ return; }
            statusDisplay.textContent = 'AI Thinking...'; aiTextDisplay.textContent = '...';
            try {
                const response = await fetch(TOGETHER_AI_URL, {/*...*/});
                if (!response.ok) {/*...*/ throw new Error(/*...*/); }
                const data = await response.json();
                const aiResponseText = data.choices?.[0]?.message?.content?.trim();
                if (aiResponseText) { aiTextDisplay.textContent = aiResponseText; speakAI(aiResponseText); }
                else { throw new Error("Empty AI response."); }
            } catch (error) {
                console.error('Error fetching AI response:', error); statusDisplay.textContent = `Error API: ${error.message}`;
                aiTextDisplay.textContent = `Failed AI response. ${error.message}`; isProcessing = false;
                updateStatusDisplay(); updateManualButtonStates();
            }
        }

        function speakAI(textToSpeak) { /* ... (Kode speakAI sama, termasuk onend reset timer) ... */
             if (!synthesis || !textToSpeak) { console.warn("TTS skip."); isProcessing = false; updateStatusDisplay(); updateManualButtonStates(); return; }
             if (isSpeakingAI || synthesis.speaking) { synthesis.cancel(); }
             currentUtterance = new SpeechSynthesisUtterance(textToSpeak); currentUtterance.lang = 'id-ID';
             try { let v = synthesis.getVoices(); if(v.length>0){const iv=v.find(vo=>vo.lang==='id-ID'); if(iv) currentUtterance.voice=iv;} } catch(e){}
             currentUtterance.onstart=()=>{ console.log("AI Speech start."); isSpeakingAI=true; isProcessing=false; updateStatusDisplay(); updateManualButtonStates(); };
             currentUtterance.onend=()=>{ console.log("AI Speech end."); isSpeakingAI=false; currentUtterance=null; updateStatusDisplay(); updateManualButtonStates(); resetDetectionTimers(); };
             currentUtterance.onerror=(e)=>{ console.error('TTS Error:', e.error); statusDisplay.textContent = `Error TTS: ${e.error}`; isSpeakingAI=false; isProcessing=false; currentUtterance=null; updateStatusDisplay(); updateManualButtonStates(); };
             synthesis.speak(currentUtterance);
        }

        function interruptAI() { /* ... (Kode interruptAI sama) ... */
            if (isSpeakingAI && synthesis.speaking) { console.log("Interrupting AI..."); synthesis.cancel();
                setTimeout(() => { if (!isListening && API_KEY && recognition && faceApiReady) { startListening(); } }, 150);
            }
        }

        // --- Fungsi Update Status & Tombol (Sama) ---
        function updateStatusDisplay() { /* ... (Kode updateStatusDisplay sama) ... */
            let currentStatus = "Unknown";
            if (!API_KEY) currentStatus = "Error: API Key?";
            else if (!faceApiReady) currentStatus = "Loading Face Detection...";
            else if (isProcessing) currentStatus = "Processing...";
            else if (isListening) currentStatus = "Listening...";
            else if (isSpeakingAI) currentStatus = "AI Speaking...";
            else currentStatus = "Ready (Auto)";
            // Jangan timpa pesan error penting dari STT/TTS/Setup
            if(!statusDisplay.textContent.toLowerCase().includes("error")) {
                 statusDisplay.textContent = currentStatus;
            } else {
                 console.log("Retaining error message in status display:", statusDisplay.textContent);
            }
        }
        function updateManualButtonStates() { /* ... (Kode updateManualButtonStates sama) ... */
             const canStartManually = API_KEY && recognition && faceApiReady && !isListening && !isSpeakingAI && !isProcessing;
             const canStopManually = isListening;
             manualStartButton.disabled = !canStartManually;
             manualStopButton.disabled = !canStopManually;
        }

        // --- Fungsi Deteksi Wajah & Trigger (Dengan Stillness Check yang Dihormati) ---
        async function setupFaceDetection() { /* ... (Kode setupFaceDetection sama) ... */
             statusDisplay.textContent = 'Loading models...'; try { await faceapi.nets.tinyFaceDetector.loadFromUri('/models'); await faceapi.nets.faceLandmark68TinyNet.loadFromUri('/models'); console.log("Models loaded."); statusDisplay.textContent = 'Requesting camera...'; const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 320, height: 240 }, audio: false }); videoElement.srcObject = stream; await new Promise((resolve) => { videoElement.onloadedmetadata = resolve; }); videoElement.play(); console.log("Webcam started."); faceApiReady = true; statusDisplay.textContent = 'Face detection ready.'; startDetectionLoop(); } catch (err) { console.error("Error setup face detection:", err); faceApiReady = false; /* ... (Error handling lebih detail sama) ... */ } finally { updateStatusDisplay(); updateManualButtonStates(); }
        }

        function startDetectionLoop() {
             if (detectionInterval) clearInterval(detectionInterval);
             detectionInterval = setInterval(async () => {
                 if (!faceApiReady || videoElement.paused || videoElement.ended) return;
                 const detectionOptions = new faceapi.TinyFaceDetectorOptions({ inputSize: 224 });
                 const detection = await faceapi.detectSingleFace(videoElement, detectionOptions).withFaceLandmarks(true);
                 const displaySize = { width: videoElement.width, height: videoElement.height };
                 canvasElement.getContext('2d').clearRect(0, 0, canvasElement.width, canvasElement.height);
                 if (detection) { const resized = faceapi.resizeResults(detection, displaySize); faceapi.draw.drawFaceLandmarks(canvasElement, resized); }

                 if (detection && detection.detection.score > faceDetectedConfidence && detection.landmarks && detection.landmarks.positions && detection.landmarks.positions.length >= 68) {
                     const positions = detection.landmarks.positions;
                     //console.log(`Detection Score: ${detection.detection.score.toFixed(2)}`); // Keep logging low unless needed

                     const upperLipBottom = positions[62].y; const lowerLipTop = positions[66].y;
                     const mouthVerticalDistance = Math.abs(lowerLipTop - upperLipBottom);
                     const currentMouthState = mouthVerticalDistance > mouthOpenThreshold ? 'open' : 'closed';
                     //console.log(`Mouth Dist: ${mouthVerticalDistance.toFixed(1)}, State: ${currentMouthState}, Thresh: ${mouthOpenThreshold}`); // Keep logging low

                     const currentHeadPosition = { x: positions[30].x, y: positions[30].y };
                     let headMoved = false;
                     if (lastHeadPosition) { const dx=currentHeadPosition.x-lastHeadPosition.x; const dy=currentHeadPosition.y-lastHeadPosition.y; const dist=Math.sqrt(dx*dx+dy*dy); if (dist > headMovementThreshold) headMoved = true; }
                     else { /*console.log(`Head Pos Initial: (${currentHeadPosition.x.toFixed(0)}, ${currentHeadPosition.y.toFixed(0)})`);*/ } // Keep logging low

                     const now = Date.now();

                     // --- Update Timer & State (Keep minimal logging) ---
                     if (currentMouthState !== lastMouthState) { if (!mouthMovementStart) mouthMovementStart = now; mouthStillStart = null; lastMouthState = currentMouthState; } else { mouthMovementStart = null; }
                     if (headMoved) { headStillStart = null; } else { if (!headStillStart) headStillStart = now; }
                     if (currentMouthState === 'closed') { if (!mouthStillStart) mouthStillStart = now; } else { mouthStillStart = null; }

                     // --- Logika Pemicu ---
                     //console.log(`[CHECK] L:${isListening}, P:${isProcessing}, S:${isSpeakingAI}, StillnessAllowed: ${stillnessCheckAllowed}`); // Keep logging low

                     // 1. Trigger Mulai Bicara / Interupsi
                     if (mouthMovementStart) {
                         const movementDuration = now - mouthMovementStart;
                         //console.log(`[CHECK] Mouth Moving Duration: ${movementDuration}ms / ${MOUTH_MOVEMENT_CONFIRM_DURATION}ms`); // Keep logging low
                         if (movementDuration >= MOUTH_MOVEMENT_CONFIRM_DURATION) {
                             console.log(`[CONDITION MET] Mouth Movement Duration!`);
                             if (!isListening && !isProcessing && !isSpeakingAI) { console.log(">>> TRIGGER: Starting STT via Mouth Movement"); startListening(); resetDetectionTimers(); }
                             else if (isSpeakingAI) { console.log(">>> TRIGGER: Interrupting AI via Mouth Movement"); interruptAI(); resetDetectionTimers(); }
                             else { /* console.log(`[SKIP TRIGGER START/INTERRUPT] App state not ready`); */ } // Keep logging low
                             mouthMovementStart = null;
                         }
                     }

                     // 2. Trigger Berhenti Bicara (Stillness - Hormati Masa Tenggang)
                     // **** MODIFIKASI DI SINI ****
                     if (isListening && stillnessCheckAllowed) { // <<< Hanya cek jika diizinkan
                         const headStillTime = headStillStart ? now - headStillStart : 0;
                         const mouthStillTime = mouthStillStart ? now - mouthStillStart : 0;
                         //console.log(`[CHECK STILLNESS (Allowed)] Head: ${headStillTime}ms/${HEAD_STILL_CONFIRM_DURATION}ms, Mouth: ${mouthStillTime}ms/${MOUTH_STILL_CONFIRM_DURATION}ms`); // Keep logging low
                         if (headStillTime >= HEAD_STILL_CONFIRM_DURATION && mouthStillTime >= MOUTH_STILL_CONFIRM_DURATION) {
                             console.log(">>> TRIGGER: Stopping STT via Stillness");
                             stopListeningAndProcess();
                             resetDetectionTimers();
                         }
                     } else if (isListening && !stillnessCheckAllowed) {
                         console.log("[CHECK STILLNESS (Blocked)] Waiting for initial grace period."); // Log saat diblokir
                     }

                     lastHeadPosition = currentHeadPosition;

                 } else {
                     /* console.log("Face not detected/low conf/incomplete landmarks."); */ // Keep logging low
                     resetDetectionTimers();
                     lastHeadPosition = null;
                 }
             }, DETECTION_INTERVAL_MS);
         }

        function resetDetectionTimers() { /* ... (Kode resetDetectionTimers sama) ... */ console.log("[TIMER] Resetting detection timers."); mouthMovementStart = null; headStillStart = null; mouthStillStart = null; }

        // --- Inisialisasi Aplikasi ---
        async function initializeApp() { /* ... (Kode initializeApp sama, termasuk initial mic check opsional) ... */
            statusDisplay.textContent = 'Fetching config...'; manualStartButton.disabled = true; manualStopButton.disabled = true;
            await getApiKey();
            if (API_KEY && typeof faceapi !== 'undefined') { await setupFaceDetection(); } // Cek faceapi juga
            else if (!API_KEY) { statusDisplay.textContent = "Init failed (API Key)."; }
            else { statusDisplay.textContent = "Error: face-api.js?"; alert("face-api.js failed to load."); }
            updateStatusDisplay(); updateManualButtonStates(); console.log("Init attempt complete.");
            // Initial mic check optional
            if (recognition && API_KEY && faceApiReady) { navigator.mediaDevices.getUserMedia({audio: true}).then(s=>{console.log("Initial mic OK.");s.getTracks().forEach(t=>t.stop());}).catch(e=>{console.warn("Initial mic check fail/denied.",e.name);if(e.name==='NotAllowedError'){statusDisplay.textContent="Error: Mic Denied"; alert("Mic access denied.");}}); }
        }

        // --- Event Listener Tombol Manual (Sama) ---
        manualStartButton.addEventListener('click', () => { /* ... */ });
        manualStopButton.addEventListener('click', () => { /* ... */ });

        // Jalankan inisialisasi
        document.addEventListener('DOMContentLoaded', initializeApp);

        // --- JavaScript Ends Here ---
    </script>
</body>
</html>
